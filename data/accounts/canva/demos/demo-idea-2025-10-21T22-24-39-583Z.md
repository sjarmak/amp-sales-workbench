# Demo/Trial Plan: Canva

**Generated**: 10/21/2025

## Demo Script

**Title**: Amp Enterprise Demo: Agentic Coding for Complex Codebases
**Duration**: 50 minutes
**Target Audience**: Engineering Leadership (VP Engineering, CTO), Senior/Principal Engineers, DevOps/Platform Engineering, InfoSec/Compliance

### Objectives

- Demonstrate Amp's multi-model approach delivering superior code quality vs single-model tools
- Show predictable cost structure through usage-based pricing with transparency
- Prove time savings on real-world tasks: legacy code modernization, testing automation, documentation
- Highlight enterprise security: SSO, zero data retention, SOC 2 Type II compliance

### Demo Flow

#### 1. The Multi-Tool Problem: Why One IDE Copilot Isn't Enough (5 minutes)

**Customer Pain Point**: Teams are using 3-4 different AI coding tools (Cursor, Copilot, Codex) with unpredictable costs and inconsistent results

**Features to Showcase**:
- Current tool sprawl: Cursor for editing, Copilot for completions, ChatGPT for debugging
- Cost unpredictability: Flat per-seat pricing whether developers use it 1 hour or 100 hours per month
- Model lock-in: Cursor locked to Anthropic, Copilot locked to OpenAI - missing out on best-in-class models

**Talking Points**:
- From our conversations with 500+ engineering teams, we see developers juggling 3-4 AI tools daily
- You mentioned your team uses Cursor, GitHub Copilot, and Gemini CLI - that's $150/user/month minimum with zero cost control
- Amp consolidates this into ONE platform with usage-based pricing - you only pay for what you actually use
- Our multi-model approach means you automatically get GPT-4.5 for deep reasoning, Claude Sonnet 4.5 for fast code generation - no manual switching

#### 2. Live Demo: Legacy Java Migration with Agentic Workflow (15 minutes)

**Customer Pain Point**: Legacy codebase modernization taking months with junior developers unable to understand 10+ year old code

**Features to Showcase**:
- Multi-repo context: Index and search across 50+ microservices simultaneously
- Agentic debugging: Amp recursively searches git history to find root cause of framework upgrade failures
- Automated refactoring: Convert Java 8 â†’ Java 17 with compatibility testing built-in
- Sub-agents: Parallel task execution across multiple files/services without context pollution

**Talking Points**:
- Let's tackle a real-world scenario: upgrading a legacy Java service from Java 8 to 17
- Notice how Amp automatically creates a work tree, runs compatibility checks, and iterates on failures
- This is what your team described: 'We bumped Quarkus framework and builds failed - spent days debugging'
- With Amp's git history analysis and sub-agents, we identify breaking changes in 20 minutes vs 2 days
- Sub-agents keep your main thread clean - each task gets its own 1M token context window
- Customer result: Lab49 reduced 4-month legacy migration project to 6 weeks using this exact workflow

#### 3. Cost Transparency: Usage Dashboard and Predictable Budgeting (8 minutes)

**Customer Pain Point**: No visibility into who's using tools or how much - billing surprises at month-end

**Features to Showcase**:
- Real-time usage dashboard: See token consumption by user, team, project
- Cost controls: Set monthly budgets per team with alerts at 80% threshold
- Model pricing transparency: Show exactly which model was used and why
- Token estimation: Pre-flight cost estimates before running large refactorings

**Talking Points**:
- You mentioned 'We don't know if this will cost 2X or 10X our current spend' - let's solve that
- This dashboard shows LIVE usage across your entire org - no billing surprises
- Set team budgets: Give your senior engineers $500/month credits, junior engineers $150/month
- Unlike flat per-seat pricing where inactive users cost the same as power users, you only pay for actual usage
- Typical customer saves 30-40% vs Cursor/Copilot because not all 500 devs use AI tools equally
- FactSet case: They audit MAU billing monthly - we provide CSV exports with every billable action logged

#### 4. Enterprise Security: Zero Trust Architecture (7 minutes)

**Customer Pain Point**: Security team blocking multi-tenant SaaS tools due to data residency and compliance requirements

**Features to Showcase**:
- Zero data retention: Your code never trains our models or persists beyond session
- SSO/SAML: Integrate with Okta, Azure AD, Google Workspace
- SOC 2 Type II certified: Annual audits with reports available
- MCP integration: Connect to internal tools (Jira, Confluence, internal LLMs) without exposing data

**Talking Points**:
- Security is your #1 blocker - you said 'We can't use multi-tenant GCP for proprietary code'
- Amp enterprise tier guarantees zero data retention - inputs/outputs purged after session ends
- We're SOC 2 Type II certified with dedicated security portal for your InfoSec review
- SSO with SAML means centralized access control - revoke credentials instantly when engineers offboard
- MCP integration lets you connect internal systems (like your proprietary LLMs) without data exfiltration
- Deutsche Bank and other Tier-1 financial institutions trust Amp with their most sensitive codebases

#### 5. Differentiation: Why Amp vs Cursor/Codex/Copilot (10 minutes)

**Customer Pain Point**: Already invested in Cursor and GitHub Copilot - need compelling reason to switch

**Features to Showcase**:
- Model agnosticism: Best model for each task (GPT-4.5 reasoning + Claude editing + Gemini search)
- Agentic architecture: True autonomous workflows with sub-agents, not just autocomplete
- CLI + IDE + Web: Works everywhere developers are (VS Code, JetBrains, terminal, browser)
- Sourcegraph Code Search integration: 500M+ LOC indexed for semantic search across all repos

**Talking Points**:
- Cursor locks you into Anthropic models, Copilot into OpenAI - what happens when a better model launches?
- Amp automatically routes tasks to the best model: Unit tests use GPT-4.5, refactoring uses Claude Sonnet 4.5
- True agentic behavior: Cursor edits files, Amp orchestrates multi-file changes, runs tests, opens PRs autonomously
- Works in VS Code, IntelliJ, CLI, web browser - your team isn't all on the same IDE
- If you're already a Sourcegraph customer, Amp integrates with Code Search for instant semantic codebase understanding
- Mitchell Hashimoto (creator of Terraform/Vagrant) publicly stated Amp is 'the most credible independent agentic coding tool'

#### 6. Q&A and Trial Setup (5 minutes)

**Customer Pain Point**: 

**Features to Showcase**:

**Talking Points**:
- What questions can I answer about pricing, security, or capabilities?
- Would a 2-week trial with 10-15 of your power users be helpful?
- We can set you up with $1,000 in credits (upgrades you to Enterprise tier with SSO + zero retention)
- Typical trial includes: 1 kickoff workshop, office hours Q&A, dedicated Slack channel
- If results are positive, we offer partial Cody/Copilot seat swaps to minimize budget impact

## Trial Plan

**Duration**: 14 days

### Scope

- 15 users: Mix of 5 senior engineers (power users), 5 mid-level engineers, 5 junior/new engineers
- Use cases: Legacy code refactoring, automated test generation, documentation creation, debugging complex issues
- Enterprise tier access: SSO integration, zero data retention, dedicated support
- $1,000 in credits (approximately 3-5M tokens depending on model mix)
- Full access to all models: GPT-4.5, Claude Sonnet 4.5, Gemini Pro 1.5

### Data Requirements

- SSO details: IdP provider (Okta/Azure AD/Google), SAML configuration contact
- Development environment details: Primary IDEs (VS Code, IntelliJ, etc.), languages (Java, Python, TypeScript, etc.)
- Codebase info: Number of repos, lines of code, monorepo vs multi-repo
- Current AI tool usage: Who uses what today (Cursor, Copilot, etc.) and monthly spend
- Sample use cases: 2-3 real tasks for trial participants (e.g., migrate API endpoint, add test coverage, debug production issue)

### Setup Steps

1. **Kickoff Workshop (Day 0)** (sourcegraph, ~60 minutes)
   60-minute live session with trial participants. Cover best practices: agents.md configuration, context management, sub-agents, when to use Oracle feature. Live demo of 2-3 common workflows.

2. **SSO Configuration (Day 0-1)** (customer, ~2-4 hours)
   Customer provides SAML metadata. Sourcegraph configures SSO integration and tests with 1-2 pilot users before full rollout.

3. **IDE Plugin Installation (Day 1)** (customer, ~15 minutes per user)
   Trial participants install Amp extensions for their IDEs (VS Code, JetBrains). Sourcegraph provides installation guide and troubleshooting support via Slack.

4. **Baseline Metrics Collection (Day 1-2)** (customer, ~1 hour)
   Track 'before Amp' metrics: Time to complete sample refactoring task, lines of code written per day, test coverage added per sprint. Use same metrics post-trial for comparison.

5. **Active Trial Period (Day 2-12)** (both, ~10 days)
   Users work on real projects with Amp. Sourcegraph monitors usage dashboard, flags low-adoption users for additional training. Mid-trial check-in on Day 7 to address blockers.

6. **Usage Review & Feedback (Day 12-13)** (sourcegraph, ~2 hours)
   Sourcegraph prepares usage report: tokens consumed, cost breakdown by user/team, most common workflows. Customer surveys trial participants on satisfaction (1-10 scale).

7. **Final Presentation & Decision (Day 14)** (both, ~60 minutes)
   Present trial results: Productivity gains, cost analysis, user feedback. Discuss contract options: Full rollout, phased rollout, seat swap from existing tools.

### Success Metrics

- Productivity: 30%+ reduction in time to complete refactoring tasks vs baseline (measured with 3 sample tasks)
- Adoption: 80%+ of trial users log in 5+ times during 14-day period
- Satisfaction: Average 8/10 or higher on post-trial survey (5 questions on ease of use, code quality, time savings)
- Cost predictability: Actual spend within 20% of estimated spend (based on power user projections)
- Code quality: PRs from Amp-generated code have 90%+ merge rate (vs team average)
- Security validation: InfoSec sign-off on zero retention policy and data handling practices

## POC Scope

**Duration**: 30 days

### Technical Requirements

- SSO provider: Okta, Azure AD, Google Workspace, or SAML 2.0 compatible IdP
- Network access: Allow outbound HTTPS to *.sourcegraph.com (GCP-hosted, no on-premise deployment available)
- Development tools: VS Code 1.85+, JetBrains 2023.2+, or terminal access for CLI usage
- Git hosting: GitHub, GitLab, Bitbucket, or Azure DevOps (for PR creation and code search integration)
- Minimum $5,000 credit commitment for Enterprise tier features (SSO, zero retention, dedicated support)

### Integration Points

- Identity: SSO/SAML 2.0 for authentication, supports SCIM for user provisioning
- Code hosting: GitHub/GitLab/Bitbucket APIs for PR creation, code search indexing
- Observability: Webhook integration to customer analytics (PostHog, Amplitude) for usage tracking
- Internal tools: MCP (Model Context Protocol) to connect Jira, Confluence, internal wikis, custom LLMs
- Billing: Monthly usage CSV exports with per-user token consumption, suitable for chargeback models

### Deliverables

- Production-ready Amp deployment with SSO, zero retention, and 50-100 active users
- Custom agents.md templates for common workflows (refactoring, testing, documentation)
- Usage analytics dashboard: Real-time cost tracking, adoption metrics, model usage breakdown
- ROI report: Quantified time savings, cost comparison vs existing tools, productivity gains per team
- Best practices guide: Context management, sub-agent usage, when to use Oracle, avoiding common pitfalls
- Integration examples: MCP connectors for Jira (ticket context), Confluence (documentation), internal LLMs
- Executive summary: Business case for full rollout including cost projections, risk mitigation, rollout plan

### Success Criteria

- Security approval: InfoSec sign-off on data handling, zero retention policy, SOC 2 audit review
- Cost efficiency: Average cost per active user under $150/month (vs $250-300/month for Cursor + Copilot)
- Productivity gain: Measurable 25%+ reduction in time-to-completion for refactoring, testing, or documentation tasks
- Adoption rate: 60%+ of provisioned users active at least 10 days per month
- Quality validation: 85%+ of Amp-generated PRs approved without major rework
- Stakeholder buy-in: Engineering leadership and finance approve budget for full rollout
- Clear ROI path: POC results extrapolated to full developer population show positive ROI within 6 months

### Timeline

**Week 1: Onboarding & Setup** (5 business days)
- Day 1: Kickoff call with engineering leadership, platform team, InfoSec - align on goals and success criteria
- Day 2-3: SSO integration and user provisioning (up to 50 users)
- Day 3: Amp training workshop (90 minutes) covering agents.md, context management, sub-agents, Oracle feature
- Day 4-5: Users install IDE plugins, complete 2-3 tutorial exercises, ask questions in dedicated Slack channel
_Milestone: All users onboarded, SSO functional, training complete, ready for real-world usage_

**Week 2-3: Active Usage & Iteration** (10 business days)
- Users work on real projects: refactoring legacy code, adding test coverage, generating documentation
- Daily usage monitoring: Flag low-adoption users for additional support, identify common friction points
- Mid-POC check-in (Day 10): Review usage data, gather feedback, adjust workflows based on learnings
- Create custom agents.md templates for top 3 use cases identified during first 10 days
- Office hours (2x per week): Live Q&A sessions with Sourcegraph solutions engineers
_Milestone: 50+ users actively using Amp, custom workflows established, initial productivity gains visible_

**Week 4: Metrics, ROI Analysis & Expansion Planning** (5 business days)
- Compile usage analytics: Total tokens consumed, cost breakdown by user/team/model, adoption rates
- User surveys: Satisfaction scores, feature requests, pain points, comparison to existing tools
- Productivity analysis: Time savings on sample tasks (refactoring, testing, documentation)
- InfoSec review: Final security validation, any outstanding questions addressed
- Executive presentation: ROI report, cost projections for full rollout, phased adoption plan
- Contract negotiation: Seat swap options (trade Cody/Copilot licenses for Amp credits), volume discounts
_Milestone: POC report delivered, executive buy-in secured, rollout plan and budget approved_

## Customization Notes

- Based on call transcripts, COST PREDICTABILITY is #1 concern - emphasize usage-based pricing and dashboard transparency throughout demo
- Security requirements vary: Intel wants on-premise (not possible), CME needs air-gapped (not possible), but most accept multi-tenant GCP with zero retention guarantee
- Common competitor stack: Cursor + GitHub Copilot + Gemini CLI - position Amp as consolidation play with better results and lower total cost
- Power users (like Grab engineers) multitask with multiple agents - highlight sub-agents feature to avoid context pollution and token waste
- Legacy code modernization is high-value use case: Java 8â†’17, framework upgrades (Quarkus example), SQL compatibility testing
- Testing automation resonates: Generate unit tests, integration tests, test plans from existing code - reduces manual QA burden
- MCP integration differentiator: Connect to Jira for ticket context, Confluence for documentation, internal LLMs for proprietary models
- Trial setup blockers: SSO takes 2-4 hours (not weeks), need $1K minimum for Enterprise tier, InfoSec review typically 1-2 weeks
- Amp works in VS Code, JetBrains, CLI, web browser - competitors like Cursor are IDE forks (less flexible)
- Model agnosticism is key selling point: Auto-route tasks to best model (GPT-4.5 reasoning, Claude Sonnet coding, Gemini search) vs locked into one model family
- Reference customers: Lab49 (60% faster refactoring), Mitchell Hashimoto (public endorsement), Deutsche Bank/Tier-1 banks use Amp
- Pricing negotiation: Typical enterprise wants 70-80% discount off list, but Amp has narrow margins - best leverage is seat swaps from existing tools

